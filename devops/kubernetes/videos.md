# Videos related to K8s

- [I just want mTLS](https://kube.fm/i-just-want-mtls-john)
- [Karpenter for Kubernetes Tutorial with Demo](https://youtu.be/cc2leue9P3s?si=fu93cIpb9xuS-wUn)
    - HPA
    - Node scaler (CA/Karpenter): Periodically checks for pending/unschedulable pods
    - Cluster Autoscaler challenges
        - Node Provision latency
        - Biggest challenge is nodegroup management
    - Karpenter
        - Efficient Node Autoscaler for Kubernetes
        - Created by AWS, but opensource
        - Automatically launches appropriate worker nodes without node groups
        - Karpenter is Kubernetes Native
            - YAML support
            - Respects Kubernetes scheduling
        - Directly calls EC2 API for suitable EC2 instances
        - Provision appropriate instances on podspec without separate nodegroups
        - With ASG, only compatible instance types can be used
        - Karpenter supports diverse instance types including machine learning and generative AI workloads
    - You can usually maintain karpenter with two resource type: Nodepool and Ec2NodeClass
    - Containers scaling requirements
        - memory
        - CPU
        - GPU
    - NodePool Yaml
        - YAML file
        - Defines what kind of nodes Karpenter will create
        - Define instance types, CPU architecture, number of cores, certain AZs for nodes that Karpenter will respect
        - Instance family option
        - Instance type option
        - Purchase options flexibility
        - CPU architecture flexibility
        - Taints can be added with NodePool
        - Karpenter automatically adds the well-known labels to the provisioned nodes
        - Karpenter supports GPU
        - You can mention additional labels inside the metadata sections
        - Karpenter respects all the scheduling constraints like: Node Selector, Node Affinity, Taints and tolerations, Topology spread
    - Kubernetes Scheduling
        - The Kubernetes scheduler is a control-plane process which assigns Pods to Nodes. The scheduler determines which Nodes are valid placements for each Pod in the scheduling queue according to constraints and available resources. The scheduler then ranks each valid Node and binds the Pod to a suitable Node.
    - Karpenter optimization
        - Enable consolidation
            - Turn on the flag disruption.consolidationPolicy: WhenUndeutilized
            - consolidateAfter: 30s
- [How Kubernetes really works: Contributors, governance, and hidden complexity, with Bob Killen](https://youtu.be/pY9BF7z5fJs?si=N-qSbkihwIjhK0tQ)
- [More Kubernetes Than I Bargained For, with Amos Wenger](https://youtu.be/ZHO5b5mKT7w?si=ezZWXXg58GgZ1e4i)
- [The Karpenter Effect: Redefining Kubernetes Operations, with Tanat Lokejaroenlarb](https://youtu.be/HoxHcf9Wl7k?si=nE6S-Dcw_5wrN79a)
- [Cgroups, namespaces, and beyond: what are containers made from?](https://youtu.be/sK5i-N34im8?si=kKkSG6UnQAVVVo1Z)
    - What is container?
        - It's not quite like a VM
            - Uses the host kernal
            - Can't boot a different OS
            - Can't have its own modules
            - Doesn't need init as PID 1
        - It's just normal processes on the host machine
        - Containers are not in the Kernal. What is in the kernal is actually are the famous cgroups and namespaces
    - The building blocks
    - Container runtimes
    - **Different Cgroups**:
        - Memory Cgroup: Accounting
            - Keeps track of pages used by each group
                - file (read/write/mmap from block devices)
                - anonymous (stack, heap, anonymous mmap)
                - active (Recently accessed)
                - inactive (candidate for eviction)
            - Each page is charged to a group
            - Pages can be shared across multiple groups
                - Multiple processes reading from the same files
        - Memory cgroup: limits
            - Each group can have its own limits
            - Soft limits are not enforced
            - Hard limits will trigger a per-group OOM killer
            - Limits can be set for different kinds of memory
                - physical memory
                - kernel memory
                - total memory
        - Memory cgroup: tricky details
            - Each time the kernal gives a page to a process, or takes it away, it updates the counters
            - This adds some overhead
            - This cannot be enabled/disabled per process
            - When multiple groups use the same page, only the first one is charged. But if it stops using it, the charge is moved to another group
        - HugeTLB cgroup
        - CPU cgroup
            - keeps track of user/system CPU time
            - keeps track of usage per CPU
            - Allows to set weights
            - Can't set CPU limits
        - Cpuset cgroup
            - Pin groups to specific CPU(s)
            - Reserve CPUs for specific apps
            - Avoid processes bouncing between CPUs
            - Also relevant for NUMA systems
            - NUMA (Non uniform memory architecture)
        - Blkio cgroup
            - Keeps track of I/Os for each group
                - per block device
                - read vs write
                - sync vs async
            - Set throttle (limits) for each group
                - per block device
                - read vs write
                - ops vs bytes
            - Set relative weights for each group
            - Note: most writes go through the page cache. So classic writes will appear  to be unthrottled at first
            




